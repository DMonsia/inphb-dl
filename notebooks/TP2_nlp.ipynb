{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sustained-tender",
   "metadata": {},
   "source": [
    "#  TP 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-reference",
   "metadata": {},
   "source": [
    "### 0. Décompressez le fichier amazon_reviews2020.zip  du dossier `nlp_datasets`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-transition",
   "metadata": {},
   "source": [
    "### 1. Construction du dataloader pour ce jeu de données.\n",
    "\n",
    "* En regardant les premières lignes de code de ce notebook, réécrivez l'import de package permettant d'accéder aux différentes méthodes et classes utiles au traitement de texte.\n",
    "\n",
    "* Exécutez ce morceau de code: `tknzer = WordTokenizer(); tkner(\"j'aime la Data Science\")`.\n",
    "* Inspectez les paramètres du constructeur WordTokenizer, adaptez-le au français puis re-excuter la commande précédente. Que constatez-vous ?\n",
    "* En recherchant `TextBlock` dans la [documentation de fastai](https://docs.fast.ai/) et suivant la procédure de construction du dataloader suivant l'API DataBlock (dans ce notebook), instanciez un dataloader pour le corpus des critiques contenu dans le fichier `dataset_fr_train.json`. *N.B: le tokenizer par défaut considère que le corpus est en anglais. La classe `TextBlock` prend en charge les dataframes !*\n",
    "* ÉvoqueZ la méthode `show_batch()` pour visualiser un lot de données et aussi l'attribut `sum` du dataloader obtenu qui présente un résumé. Vérifiez bien que le corpus a été correctement tokenisé."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-absorption",
   "metadata": {},
   "source": [
    "### 2. Construction d'un modèle de langage\n",
    "\n",
    "* Téléchargez le modèle pré-entraîné sur une version réduite de wikipédia en français à l'adresse: \n",
    "  https://drive.google.com/uc?id=1CN6QqTxnTy_UHVTaIqc53mwSVpJJZtbN. Décompressez le fichier avec la commande\n",
    "* En consultant la documentation de la fonction `language_model_learner`, instanciez un objet `learn` à partir de à partir des paramètres du modèle pré-entraîné.\n",
    "* Générer du texte à partir de modèle comme dans la section \"Text Generation\" du notebook `lesson3_nlp`. Essayer des phrases générales puis des phrases semblables aux critiques du jeu de données `amazon_reviews2020`. Que constatez-vous ?\n",
    "* Entraînez (Affinez) ce modèle pendant une époque comme dans le notebook de cours puis générez du texte comme dans la question précédente. Comparez les textes générés à ceux de la questions précédente. L'apprentissage a-t-il eu un effet perceptible sur la qualité de la génération.\n",
    "* Peaufinez le modèle pour l'analyse sentimentale basée sur le champ `stars` du jeu de données."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
